#!/usr/bin/env python
# -*- coding: utf-8 -*-
import cv2
import time
import math
import socket
import threading
import numpy as np
from collections import deque
from . import SingleStickSSDwithUSBCamera_OpenVINO_NCS2_robot as SSD
import sys
import termios
import tty
import serial

class TargetFeature(SSD.DetectionObject):
    center = [0, 0]
    area = 0
    img = None
    gray_img = None
    keypoints = None
    def __init__(self, target, target_img, keypoint_list):
        self.box_left = target.box_left
        self.box_top = target.box_top
        self.box_right = target.box_right
        self.box_bottom = target.box_bottom
        self.class_name = target.class_name
        self.confidence = target.confidence
        self.center = [(target.box_left + target.box_right)/2, (target.box_top + target.box_bottom)/2]
        self.area = (target.box_right - target.box_left) * (target.box_bottom - target.box_top)
        self.img = target_img
        self.gray_img = cv2.cvtColor(target_img, cv2.COLOR_BGR2GRAY)
        self.keypoints = keypoint_list

class Follow(threading.Thread):
    def __init__(self, name, follow_instruction, camera_id = 0, connect_motor=False, display=False, log=False):
        threading.Thread.__init__(self)
        self.id = '[' + name + ']'
        self.follow_instruction = follow_instruction
        self.camera_id = camera_id
        self.connect_motor = connect_motor
        self.display = display
        self.log = log
        self.decison_socket = None
        self.action_dict = {'straight':0, 'stop':0, 'left':5, 'right':-5}
        self.prev_position = deque(maxlen = 10)
        self.prev_instruction = deque(maxlen = 10)
        self.x = 0
        self.y = 0
        self.missing_count = 0
        self.match_check = 0
        self.frame_center = [0, 0] # [x, y] frame center point
        self.orb = cv2.ORB.create()
        self.bf = cv2.BFMatcher(normType=cv2.NORM_HAMMING)

    def run(self):
        if self.connect_motor is True:
            self.connect_motor_setting()
        if self.display is True:    
            cv2.namedWindow("Follow", cv2.WINDOW_NORMAL)
            cv2.resizeWindow("Follow", 640, 360)
        if self.log is True:
            self.log_file = open('follow.log', 'w')

        self.camera_init(camera_width=960, camera_height=540, camera_fps=30, camera_id = self.camera_id)
        frame = self.get_frame()
        if frame is None:
            self.print_msg("Camera or Video can't open!!!")
            return
        for i in range(0, 10):
            self.prev_instruction.appendleft(("stop", 0))

        while(True):
            try:
                # get camera image
                start_time = time.time()
                frame = self.get_frame()
                objects = self.person_detect(frame)
                self.print_msg("It takes %s second to detect human.\n" % str(time.time() - start_time))
                target = self.target_search(frame, objects)
                self.print_msg("It takes %s second to search target.\n" % str(time.time() - start_time))
                if target is None:
                    self.print_msg("Can't find target.")
                    self.missing_count += 1
                    self.print_msg("Missing count: ", self.missing_count)
                    if self.missing_count > 8:
                        direction = self.prev_instruction[0][0]
                        if self.prev_instruction[0][0] is not "right" or self.prev_instruction[0][0] is not "left":
                            if len(self.prev_position) < 5:
                                direction = "stop"
                            else:
                                direction = "right"
                        data = direction + ' ' + str(0)
                        if self.connect_motor is True:
                            self.motor_control([0, self.action_dict[direction]])
                        else:
                            self.follow_instruction.appendleft([0, self.action_dict[direction]])
                        self.print_msg("Send follow instruction to server!", data)
                    else:
                        data = self.prev_instruction[0][0] + ' ' + str(self.prev_instruction[0][1])
                        if self.connect_motor is True:
                            self.motor_control([self.prev_instruction[0][1], self.action_dict[self.prev_instruction[0][0]]])
                        else:
                            self.follow_instruction.appendleft([self.prev_instruction[0][1], self.action_dict[self.prev_instruction[0][0]]])
                        self.print_msg("Send follow instruction to server!", data)
                else:
                    self.missing_count = 0
                    instruction = self.make_instruction(target)
                    # send instruction
                    data = instruction[0] + ' ' + str(instruction[1])
                    if self.connect_motor is True:
                        self.motor_control([self.action_dict[instruction[0]], instruction[1]])
                        self.prev_instruction.appendleft([instruction[0], instruction[1]])
                    else:
                        self.follow_instruction.appendleft([instruction[1], self.action_dict[instruction[0]]])
                        self.prev_instruction.appendleft([instruction[0], instruction[1]])
                    self.print_msg("Send follow instruction to server!", data)
                    self.print_msg("Detect object in total area rate:", target.area / (self.x * self.y))
                    self.print_msg("Frame & x & y:", target.box_left, target.box_right-target.box_left, target.box_top, target.box_bottom-target.box_top , self.x, self.y)
                    self.print_msg("It takes %s second to make instruction.\n" % str(time.time() - start_time))
                    if self.display is True:
                        cv2.rectangle(frame, (target.box_left, target.box_top), (target.box_right, target.box_bottom), (0,0,255), 2)
                        cv2.rectangle(frame, (self.prev_position[-2].box_left, self.prev_position[-2].box_top),
                                         (self.prev_position[-2].box_right, self.prev_position[-2].box_bottom), (0,255,0), 2)
                        cv2.putText(frame, data, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 1, cv2.LINE_AA)
                        cv2.putText(frame, "Area rate: " + str(target.area / (self.x * self.y)), (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 1, cv2.LINE_AA)
                        cv2.circle(frame, (int(target.center[0]), int(target.center[1])), 7, (0,0,255), -1)
                if self.display is True:
                    cv2.line(frame, (int(self.x/2), 0), (int(self.x/2), self.y), (0,232,240), 3)
                    cv2.line(frame, (int(self.x * 0.4), 0), (int(self.x * 0.4), self.y), (27,211,218), 2)
                    cv2.line(frame, (int(self.x * 0.6), 0), (int(self.x * 0.6), self.y), (27,211,218), 2)
                    for i in range(len(self.prev_position)-1, -1, -1):
                        if self.prev_position[i-1] is None or self.prev_position[i] is None:
                            continue
                        thickness = int(np.sqrt(10/float(i+1)) * 2.5)
                        center1 = (int(self.prev_position[i].center[0]), int(self.prev_position[i].center[1]))
                        center2 = (int(self.prev_position[i-1].center[0]), int(self.prev_position[i-1].center[1]))
                        cv2.line(frame, center2, center1, (0,0,255), thickness)
                    cv2.imshow("Follow", frame)
                    cv2.waitKey(30)
                diff_time = time.time() - start_time
                self.print_msg("It takes %s second to finish a follow cycle.\n" % str(diff_time))
            except KeyboardInterrupt:
                cv2.destroyAllWindows()
                break
        pass

    def connect_motor_setting(self):
        self.ser = serial.Serial('/dev/ttyACM0' , 9600)
        self.old_settings = termios.tcgetattr(sys.stdin)
        tty.setcbreak(sys.stdin.fileno())
        if(self.ser.isOpen()):
            self.print_msg("Motor Connect")
    
    def motor_control(self, instruction):
        try:
            s = ''
            line = str(instruction[0]) + ' ' + str(instruction[1])
            self.ser.write(line.encode())
            self.ser.write('\n'.encode())
            self.print_msg('Instruction send to motor:', line)

            time.sleep(0.02)
            line = ""
            if self.ser.in_waiting:
                cin = self.ser.read(1)
                if cin != b'\n':
                    cin = cin.decode(encoding='utf-8' , errors='ignore')
                    s += cin
                else:
                    self.print_msg("Serial is received:" + s)
                    s = ""
        except KeyboardInterrupt:
            self.ser.write('0'.encode())
            self.ser.write('\n'.encode())
            self.ser.close()
            # file.close()
            if(~self.ser.isOpen()):
                self.print_msg("Serial is closed\n")

    def make_instruction(self, target):
        direction = "straight"
        value = 0
        repeat_count = 0
        tmp = self.prev_instruction[0][0]
        for inst in self.prev_instruction:
            if tmp is inst[0]:
                repeat_count += 1
            else:
                break
        if target.area > self.x * self.y * 0.35:
            direction = "stop"
            return (direction, int(value))
        elif target.area < self.x * self.y * 0.05:
            value = 22
        elif target.area < self.x * self.y * 0.20:
            value = 20
        elif target.area > self.x * self.y * 0.30:
            value = 15
        #elif target.area > self.x * self.y * 0.30:
        #    value = 12
        else:
            value = 18
        current_position = target.center
        if current_position[0] < self.x * 0.4:
            repeat_count = 0
            direction = "left"
            tmp = direction
            for inst in self.prev_instruction:
                if tmp is inst[0]:
                    repeat_count += 1
                else:
                    break
            value = 4 + repeat_count-1 + pow(2, repeat_count//4)
            value = 4
        elif current_position[0] > self.x * 0.6:
            repeat_count = 0
            direction = "right"
            tmp = direction
            for inst in self.prev_instruction:
                if tmp is inst[0]:
                    repeat_count += 1
                else:
                    break
            value = 4 + repeat_count-1 + pow(2, repeat_count//4)
            value = 4
        self.print_msg("Repeat count:", repeat_count)
        return (direction, int(value))

    def keypoint_detect(self, gray):
        try:
            kps, des = self.orb.detectAndCompute(gray, None)
        except:
            return [],[]
        return kps, des

    def keypoints_match(self, kp1, des1, kp2, des2):
        try:
            raw_matches = self.bf.knnMatch(des1, des2, k=2)
            good_matches = [m for (m, n) in raw_matches if m.distance < 0.65 * n.distance]
        except:
            return 0, 0

        good_number = len(good_matches)
        return 0, good_number

    def target_search(self, frame, objects):
        target_objects = []
        for obj in objects:
            if obj.class_name is 'person':
                target_objects.append(obj)
        if target_objects is None:
            self.print_msg("Can't detect any human!!")
            return None
        # when number of previous position is less 5
        if len(self.prev_position) < 5:
            index = 0
            distance = 999999
            want = -1
            for target in target_objects:
                if target.confidence < 0.7:
                    continue
                target_center = [(target.box_right + target.box_left)/2,
                                 (target.box_bottom + target.box_top)/2]
                # when target center between x-center of frame +- 20%
                if (target_center[0] <= self.frame_center[0] + self.x * 0.2) and (target_center[0] >= self.frame_center[0] - self.x * 0.2):
                    if abs(target_center[0] - self.frame_center[0]) < distance:
                        distance = abs(target_center[0] - self.frame_center[0])
                        want = index
                index += 1
            if want >= 0:
                target = target_objects[want]
                target_img = frame[target.box_top:target.box_bottom, target.box_left:target.box_right]
                self.print_msg("Target shape:", target_img.shape)
                if (target_img.shape[0] == 0 or target_img.shape[1] == 0):
                    return None
                kps, des = self.keypoint_detect(cv2.cvtColor(target_img, cv2.COLOR_BGR2GRAY))
                self.prev_position.append(TargetFeature(target, target_img, [kps, des]))
            return None
        else:
            result_list = []
            for j in range(len(target_objects)):
                target = target_objects[j]
                if target.confidence < 0.7:
                    continue
                target_img = frame[target.box_top:target.box_bottom, target.box_left:target.box_right]
                print(target_img.shape)
                if (target_img.shape[0] == 0 or target_img.shape[1] == 0):
                    continue
                time1 = time.time()
                kps, des = self.keypoint_detect(cv2.cvtColor(target_img, cv2.COLOR_BGR2GRAY))
                print("keypoint detect time:", time.time()-time1)
                center = [(target.box_left + target.box_right)/2, (target.box_top + target.box_bottom)/2]
                distance = 0
                total_points = 0
                if self.match_check is 2:
                    time1 = time.time()
                    for i in range(1, 3, 1):
                        match_points = self.keypoints_match(self.prev_position[-i].keypoints[0], self.prev_position[-i].keypoints[1], kps, des)
                        total_points += match_points[1]
                        distance += (np.square(center[0] - self.prev_position[-i].center[0]) + np.square(center[1] - self.prev_position[-i].center[1]))
                    result_list.append((j, distance, total_points, target_img, [kps, des]))
                    print("keypoint match time", time.time() - time1)
                else:
                    for i in range(1, 3, 1):
                        distance += (np.square(center[0] - self.prev_position[-i].center[0]) + np.square(center[1] - self.prev_position[-i].center[1]))
                    result_list.append((j, distance, total_points, target_img, [kps, des]))
            if result_list is None or len(result_list) is 0:
                return None
            if self.match_check is 2:
                self.match_check = 0
                result_list = sorted(result_list, key=lambda x: x[2], reverse=True)
                result_list = sorted(result_list, key=lambda x: x[1])
                self.prev_position.append(TargetFeature(target_objects[result_list[0][0]], result_list[0][3], result_list[0][4]))
            else:
                self.match_check += 1
                result_list = sorted(result_list, key=lambda x: x[1])
                self.prev_position.append(TargetFeature(target_objects[result_list[0][0]], result_list[0][3], result_list[0][4]))
            return TargetFeature(target_objects[result_list[0][0]], result_list[0][3], result_list[0][4])
            '''
                target_img = frame[target.box_top:target.box_bottom, target.box_left:target.box_right]
                print(target_img.shape)
                if (target_img.shape[0] == 0 or target_img.shape[1] == 0):
                    continue
                gray = cv2.cvtColor(target_img, cv2.COLOR_BGR2GRAY)
                time1 = time.time()
                kps, des = self.keypoint_detect(gray)
                print("keypoint detect time:", time.time()-time1)
                # temp condition
                count = 0
                total_points = 0
                distance = 0
                center = [(target.box_left + target.box_right)/2, (target.box_top + target.box_bottom)/2]
                time1 = time.time()
                for i in range(1, 3, 1):
                    match_points = self.keypoints_match(self.prev_position[-i].keypoints[0], self.prev_position[-i].keypoints[1], kps, des)
                    total_points += match_points[1]
                    if match_points[1] > limit_match_points:
                        count += 1
                    distance += (np.square(center[0] - self.prev_position[-i].center[0]) + np.square(center[1] - self.prev_position[-i].center[1]))
                result_list.append((j, distance, total_points, count, target_img, [kps, des]))
                print("keypoint match time", time.time() - time1)
            if result_list is None:
                return None
            distance_list = sorted(result_list, key=lambda x: x[1])
            points_list = []
            for i in range(len(distance_list)):
                if distance_list[0][1] / distance_list[i][1] > 0.85:
                    points_list.append(distance_list[i])
            final_list = sorted(points_list, key=lambda x: x[2], reverse=True)
            if len(final_list) > 0:
                index = final_list[0][0]
                self.prev_position.append(TargetFeature(target_objects[index], final_list[0][4], final_list[0][5]))
                return TargetFeature(target_objects[index], final_list[0][4], final_list[0][5])
            return None
            '''

    def person_detect(self, frame):
        objects = SSD.SSD_predict(frame)
        return objects

    def camera_init(self, camera_width = 960, camera_height = 720, camera_fps = 30, camera_id = 0):
        self.cap = cv2.VideoCapture(camera_id)
        self.cap.set(cv2.CAP_PROP_FPS, camera_fps)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, camera_width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, camera_height)
        self.x = int(camera_width / 4 * 3)
        self.y = int(camera_height / 4 * 3)
        self.frame_center = [int(camera_width / 4 * 3) // 2, int(camera_height / 4 * 3) // 2]
        self.print_msg(self.x , self.y, self.frame_center)

    def get_frame(self):
        hasFrame, frame = self.cap.read()
        if not hasFrame:
            return None
        else:
            frame = cv2.resize(frame, (self.x, self.y))
            return frame

    def print_msg(self, *args):
        print(self.id, " ".join(map(str, args)))
        if self.log is True:
            self.log_file.write(self.id + " " + " ".join(map(str, args)))

if __name__ == "__main__":
    follow_instruction = deque(maxlen = 5)
    follow_test = Follow('Follow_test', follow_instruction, connect_motor=True, display=False, log=False)
    print("Start Follow")
    follow_test.start()
